{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mari967/NLP-laboratorio/blob/master/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIPkh-SJjLdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws3DC2-LYFOc",
        "colab_type": "text"
      },
      "source": [
        "## 3 Accediendo a WordNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9nyKq77oy4F",
        "colab_type": "code",
        "outputId": "0af70569-5bc7-4e97-e48f-21d5b6da2a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from nltk.book import *\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "print(wn.synsets('dog'))\n",
        "\n",
        "#wn.synsets('dog', pos=wn.VERB)\n",
        "\n",
        "print(wn.synset('dog.n.01'))\n",
        "print(wn.synset('dog.n.02'))\n",
        "print(wn.synset('frump.n.01'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
            "Synset('dog.n.01')\n",
            "Synset('frump.n.01')\n",
            "Synset('frump.n.01')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtsGRd49DXjC",
        "colab_type": "code",
        "outputId": "64f642e3-8fa1-4f26-e406-db5a8135b407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Definicón 1: \", wn.synset('dog.n.01').definition())\n",
        "print(\"Definición 2: \", wn.synset('dog.n.02').definition())\n",
        "\n",
        "print(\"\\nsinónimos: \")\n",
        "\n",
        "for lemma in wn.synset('dog.n.01').lemmas():\n",
        "  print(\"* \",lemma.name())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Definicón 1:  a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
            "Definición 2:  a dull unattractive unpleasant girl or woman\n",
            "\n",
            "sinónimos: \n",
            "*  dog\n",
            "*  domestic_dog\n",
            "*  Canis_familiaris\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9-w6svtH50e",
        "colab_type": "code",
        "outputId": "3aecae28-bf92-4889-f32a-cb11f7486eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Lemas para el 2do sentido de dog:\n",
        "for lemma in wn.synset('dog.n.02').lemmas():\n",
        "  print(\"* \",lemma)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*  Lemma('frump.n.01.frump')\n",
            "*  Lemma('frump.n.01.dog')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xorhHvhIk2d",
        "colab_type": "code",
        "outputId": "a6e5fdbd-deaf-4afe-f873-ec0dcf955e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wn.synset('dog.n.01').examples()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the dog barked all night']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxyTgvGzs7_q",
        "colab_type": "text"
      },
      "source": [
        "## 4 Relaciones entre palabras en WordNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idQIQhmEPrej",
        "colab_type": "code",
        "outputId": "d8eb8564-79c7-469c-bc7c-4805dce1daa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "good\t=\twn.synset('good.a.01')\t\n",
        "g0 = good.lemmas()[0]\n",
        "#Antonimos de un synset\n",
        "print(\"Antonimo de good: \", g0.antonyms())\n",
        "\n",
        "print(\"\\n--------------------------------\\n DOG\\n\")\n",
        "\n",
        "#Hipónimos e hiperónimos de \"dog\"\n",
        "dog\t=\twn.synset('dog.n.01')\n",
        "print(\"Hiperónimo de dog: \", dog.hypernyms())\n",
        "print(\"Hipónimo de dog: \", dog.hyponyms())\n",
        "\n",
        "#Merónimo:\n",
        "#Se denomina merónimo a la palabra cuyo significado constituye una parte del significado total de otra palabra, denominada ésta holónimo.\n",
        "#X es merónimo de Y si X forma parte de Y\n",
        "print(\"Merónimo parte de dog: \", dog.part_meronyms())\n",
        "print(\"** Definicón de flag: \", wn.synset('flag.n.07').definition())\n",
        "print(\"Merónimo miembro de dog: \",dog.member_meronyms())\n",
        "\n",
        "#Holónimo:\n",
        "#Palabra cuya relación de significado engloba el significado de otras palabras, denominadas merónimos.\n",
        "#Ejemplo: «La palabra “leon” es el holónimo de \\“patas”, “cola”, “garras” y \"cabeza\"».\n",
        "print(\"\\nHolónimos de partes de dog:  \", dog.part_holonyms())\n",
        "print(\"Holónimos de miembro de dog: \", dog.member_holonyms())\n",
        "print(\"** Definicón de canis: \", wn.synset('canis.n.01').definition())\n",
        "print(\"** Definicón de pack: \", wn.synset('pack.n.06').definition())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antonimo de good:  [Lemma('bad.a.01.bad')]\n",
            "\n",
            "--------------------------------\n",
            " DOG\n",
            "\n",
            "Hiperónimo de dog:  [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
            "Hipónimo de dog:  [Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n",
            "Merónimo parte de dog:  [Synset('flag.n.07')]\n",
            "** Definicón de flag:  a conspicuously marked or shaped tail\n",
            "Merónimo miembro de dog:  []\n",
            "\n",
            "Holónimos de partes de dog:   []\n",
            "Holónimos de miembro de dog:  [Synset('canis.n.01'), Synset('pack.n.06')]\n",
            "** Definicón de canis:  type genus of the Canidae: domestic and wild dogs; wolves; jackals\n",
            "** Definicón de pack:  a group of hunting animals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMrj_Jq6YOFi",
        "colab_type": "text"
      },
      "source": [
        "## 5 Desambiguación de palabras por sentido (Word Sense Desambiguation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WLGQgsgYccj",
        "colab_type": "code",
        "outputId": "d184f3b7-6278-4927-baa6-d4005d4beb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#sentidos de la palabra \"bank\"\n",
        "print(\"La palabra \\\"bank\\\" tiene\", len(wn.synsets('bank')), \"sentidos.\")\n",
        "print(len(wn.synsets('bank', pos=wn.NOUN)), \"como sustantivo,\", len(wn.synsets('bank', pos=wn.VERB)), \"como verbo\\n\")\n",
        "\n",
        "#print(\"Definiciones de cada synset:\\n\")\n",
        "#for index, definition in enumerate([syn.definition() for syn in wn.synsets('bank')]):\n",
        "#  print(index,\") \", definition)\n",
        "\n",
        "bank02 = wn.synset('bank.n.02')\n",
        "print(\"\\nEl synset correcto es\", bank02, \"con la definición\\n \\\"\", bank02.definition() , \"\\\"\")\n",
        "  \n",
        "#Algoritmo de lesk\n",
        "from nltk.wsd\timport lesk\n",
        "from nltk import word_tokenize\n",
        "\n",
        "S\t=\t\"The\tbank\tcan\tguarantee\tdeposits\twill\teventually\tcover\tfuture\ttuition\tcosts\tbecause\tit invests\tin adjustable-rate\tmortgage\tsecurities.\"\n",
        "S_tok\t=\tword_tokenize(S)\n",
        "lesk_syn = lesk(S_tok,\t'bank',\t'n')\n",
        "print(\"\\nSynset con el algoritmo de Lesk:\", lesk_syn, \"\\n con la definición: \\\"\", lesk_syn.definition(),\"\\\"\\n\")\n",
        "\n",
        "l\t=\tword_tokenize((wn.synset('bank.n.05').definition()))\n",
        "m\t=\tword_tokenize((wn.synset('bank.n.02').definition()))\t\n",
        "k\t=\tset(S_tok)\n",
        "\n",
        "\n",
        "print(\"¿Por qué Lesk produjo este synset?\")\n",
        "if (len(k.intersection(l)) > len(k.intersection(m)) ):\n",
        "  syn_inter = wn.synset('bank.n.05')\n",
        "else: syn_inter = wn.synset('bank.n.02')\n",
        "print(\"La intersección de los tokens de la definición del synset\", syn_inter , \"con los tokens de la oración es mayor.\")\n",
        "\n",
        "#¿Qué cambios, de haber alguno, sugeriría para la correspondencia implementada por\n",
        "#NLTK?\n",
        "\n",
        "S0 = \"I went to the bank to deposit some money.\"\n",
        "S1 = \"She created a big mess of the birthday cake.\"\n",
        "S2 = \"In the interest of your safety, please wear your seatbelt.\"\n",
        "S3 = \"I drank some ice cold water.\"\n",
        "\n",
        "\n",
        "print(\"--------------------------\")\n",
        "\n",
        "print(\"\\nSentidos de las palabras según lo que vi en wordnet: \\n\")\n",
        "print(\" * \",S0, \"bank: n.02,  deposit: v.02\\n\", \"* \",S1, \"mess: n.01\\n\", \"* \",S2, \"wear: v.02\\n\", \"* \",S3, \"ice: n.01, cold: a.01, water: n.01\\n\",)\n",
        "\n",
        "print(\"Con el algoritmo de Lesk:\\n\")\n",
        "S0_tok\t=\tword_tokenize(S0)\n",
        "S1_tok\t=\tword_tokenize(S1)\n",
        "S2_tok\t=\tword_tokenize(S2)\n",
        "S3_tok\t=\tword_tokenize(S3)\n",
        "\n",
        "#lesk_syn = lesk(S_tok,\t'bank',\t'n')\n",
        "lesk_syn0 = lesk(S0_tok,\t'bank',\t'n')\n",
        "lesk_syn0b = lesk(S0_tok,\t'deposit',\t'v')\n",
        "\n",
        "lesk_syn1 = lesk(S1_tok,\t'mess',\t'n')\n",
        "\n",
        "lesk_syn2 = lesk(S2_tok,\t'wear',\t'v')\n",
        "\n",
        "lesk_syn3 = lesk(S3_tok,\t'ice',\t'n')\n",
        "lesk_syn3b = lesk(S3_tok,\t'cold',\t'n')\n",
        "lesk_syn3c = lesk(S3_tok,\t'water',\t'n')\n",
        "\n",
        "\n",
        "print(\"*\", S0, \": \", lesk_syn0, lesk_syn0b)\n",
        "print(\"*\", S1, \": \", lesk_syn1)\n",
        "print(\"*\", S2, \": \", lesk_syn2)\n",
        "print(\"*\", S3, \": \", lesk_syn3, lesk_syn3b, lesk_syn3c)\n",
        "\n",
        "print(\"--------------------------\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La palabra \"bank\" tiene 18 sentidos.\n",
            "10 como sustantivo, 8 como verbo\n",
            "\n",
            "\n",
            "El synset correcto es Synset('depository_financial_institution.n.01') con la definición\n",
            " \" a financial institution that accepts deposits and channels the money into lending activities \"\n",
            "\n",
            "Synset con el algoritmo de Lesk: Synset('bank.n.05') \n",
            " con la definición: \" a supply or stock held in reserve for future use (especially in emergencies) \"\n",
            "\n",
            "¿Por qué Lesk produjo este synset?\n",
            "La intersección de los tokens de la definición del synset Synset('bank.n.05') con los tokens de la oración es mayor.\n",
            "--------------------------\n",
            "\n",
            "Sentidos de las palabras según lo que vi en wordnet: \n",
            "\n",
            " *  I went to the bank to deposit some money. bank: n.02,  deposit: v.02\n",
            " *  She created a big mess of the birthday cake. mess: n.01\n",
            " *  In the interest of your safety, please wear your seatbelt. wear: v.02\n",
            " *  I drank some ice cold water. ice: n.01, cold: a.01, water: n.01\n",
            "\n",
            "Con el algoritmo de Lesk:\n",
            "\n",
            "* I went to the bank to deposit some money. :  Synset('savings_bank.n.02') Synset('deposit.v.02')\n",
            "* She created a big mess of the birthday cake. :  Synset('mess.n.04')\n",
            "* In the interest of your safety, please wear your seatbelt. :  Synset('wear.v.03')\n",
            "* I drank some ice cold water. :  Synset('ice_rink.n.01') Synset('coldness.n.03') Synset('water_system.n.02')\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNr0osXUsqiF",
        "colab_type": "text"
      },
      "source": [
        "## 6 Un poco más allá"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzpuxSzEsu8O",
        "colab_type": "code",
        "outputId": "11b6610b-58c0-459e-d87a-c7e553e9675d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from nltk.stem\timport\tWordNetLemmatizer\t\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "wnLemmatizer\t=\tWordNetLemmatizer()\n",
        "\n",
        "\n",
        "def lemmatizar_tupla_pos(tupla):\n",
        "  if (tupla[1][0] == 'V'):\n",
        "    pos = 'v'\n",
        "  else: \n",
        "    pos = 'n'\n",
        "\n",
        "  return (wnLemmatizer.lemmatize(tupla[0], pos), tupla[1])\n",
        "\n",
        "\n",
        "def funcion_match(cadena1, cadena2):\n",
        "  pos_cadena1 = nltk.pos_tag(word_tokenize(cadena1))\n",
        "  pos_cadena2 = nltk.pos_tag(word_tokenize(cadena2))\n",
        "  \n",
        "  lemma_pos_cadena1 = [lemmatizar_tupla_pos(tup) for tup in list(pos_cadena1)]\n",
        "  lemma_pos_cadena2 = [lemmatizar_tupla_pos(tup) for tup in list(pos_cadena2)]\n",
        "\n",
        "  lemma_pos_intersec = set(lemma_pos_cadena1).intersection(set(lemma_pos_cadena2))\n",
        "\n",
        "  return [tupla for tupla in list(lemma_pos_intersec) if not tupla[0] in stopwords.words('english')]\n",
        "  \n",
        "\n",
        "def nuevo_lesk(oracion, palabra):\n",
        "  intersecc_max = 0\n",
        "  \n",
        "  for index, definition in enumerate([syn.definition() for syn in wn.synsets(palabra)]):\n",
        "    if len (funcion_match(definition, oracion) ) >= intersecc_max:  #¿Es mejor comparar con >= ?\n",
        "      intersecc_max = len (funcion_match(definition, oracion) )\n",
        "      nro_definicion = index\n",
        "\n",
        "  return wn.synsets(palabra)[nro_definicion]\n",
        "\n",
        "\n",
        "def comparar_lesk(oracion, palabra):\n",
        "  print(\"*** Oración: \", oracion, \"***Palabra: \", palabra)\n",
        "  print(\"-----------------------------------------\")\n",
        "  nuevo_lesk_syn = nuevo_lesk(oracion, palabra)\n",
        "  print(\"Synset con el nuevo algorítmo de Lesk:\", nuevo_lesk_syn, \"\\n con la definición: \\\"\", nuevo_lesk_syn.definition(), \"\\\"\\n\")\n",
        "\n",
        "  S_tok\t=\tword_tokenize(oracion)\n",
        "  lesk_syn = lesk(S_tok,\tpalabra,\t'n')\n",
        "  print(\"Synset con el clásico algoritmo de Lesk:\", lesk_syn, \"\\n con la definición: \\\"\", lesk_syn.definition(), \"\\\"\\n\")\n",
        "  \n",
        "\n",
        "\n",
        "#---------------------------------------- CASOS DE PRUEBA\n",
        "\n",
        "comparar_lesk(\"I went to the bank to deposit some money.\", 'bank')\n",
        "comparar_lesk(\"a huge bank of earth\", 'bank')\n",
        "comparar_lesk(\"She created a big mess of the birthday cake\", 'mess')\n",
        "comparar_lesk(\"In the interest of your safety, please wear your seatbelt\", 'wear')\n",
        "comparar_lesk(\"I drank some ice cold water\", 'ice')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Oración:  I went to the bank to deposit some money. ***Palabra:  bank\n",
            "-----------------------------------------\n",
            "Synset con el nuevo algorítmo de Lesk: Synset('deposit.v.02') \n",
            " con la definición: \" put into a bank account \"\n",
            "\n",
            "Synset con el clásico algoritmo de Lesk: Synset('savings_bank.n.02') \n",
            " con la definición: \" a container (usually with a slot in the top) for keeping money at home \"\n",
            "\n",
            "*** Oración:  a huge bank of earth ***Palabra:  bank\n",
            "-----------------------------------------\n",
            "Synset con el nuevo algorítmo de Lesk: Synset('deposit.v.02') \n",
            " con la definición: \" put into a bank account \"\n",
            "\n",
            "Synset con el clásico algoritmo de Lesk: Synset('bank.n.09') \n",
            " con la definición: \" a building in which the business of banking transacted \"\n",
            "\n",
            "*** Oración:  She created a big mess of the birthday cake ***Palabra:  mess\n",
            "-----------------------------------------\n",
            "Synset con el nuevo algorítmo de Lesk: Synset('mess.v.02') \n",
            " con la definición: \" make a mess of or create disorder in \"\n",
            "\n",
            "Synset con el clásico algoritmo de Lesk: Synset('mess.n.04') \n",
            " con la definición: \" a meal eaten in a mess hall by service personnel \"\n",
            "\n",
            "*** Oración:  In the interest of your safety, please wear your seatbelt ***Palabra:  wear\n",
            "-----------------------------------------\n",
            "Synset con el nuevo algorítmo de Lesk: Synset('wear.v.09') \n",
            " con la definición: \" put clothing on one's body \"\n",
            "\n",
            "Synset con el clásico algoritmo de Lesk: Synset('wear.n.03') \n",
            " con la definición: \" the act of having on your person as a covering or adornment \"\n",
            "\n",
            "*** Oración:  I drank some ice cold water ***Palabra:  ice\n",
            "-----------------------------------------\n",
            "Synset con el nuevo algorítmo de Lesk: Synset('ice.v.03') \n",
            " con la definición: \" put ice on or put on ice \"\n",
            "\n",
            "Synset con el clásico algoritmo de Lesk: Synset('ice_rink.n.01') \n",
            " con la definición: \" a rink with a floor of ice for ice hockey or ice skating \"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}